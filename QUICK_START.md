# ğŸš€ Bull Bot - Quick Start (Updated for Vercel)

## âœ… What's Configured

Everything is set up for **Vercel-only deployment** (simpler than AWS):

- âœ… API keys configured
- âœ… All dependencies installed
- âœ… Vercel deployment files created (`vercel.json`, `api/index.py`)
- âœ… No Express server needed (simplified architecture)

---

## âš ï¸ Complete These 2 Steps First

### 1. Create Pinecone Index (5 min)
   - Go to https://app.pinecone.io/
   - Create index: `bullbot`, dimensions: `384`, metric: `cosine`

### 2. Fix OpenAI API 
   - Add credits at https://platform.openai.com/account/billing
   - OR update key in `flaskServer/config.py`

### 3. Upload Data
```bash
python upload_to_pinecone.py
```

---

## ğŸ  Local Development (2 terminals)

### Terminal 1: Flask API
```bash
cd /Users/maazinshaikh/Desktop/Mac/Programs/AskRocky/bullbot
python api/index.py
```

### Terminal 2: Vite Client
```bash
cd client
npm run dev
```

### Test
Open http://localhost:5173

---

## â˜ï¸ Deploy to Vercel (Production)

### One-Time Setup
```bash
npm install -g vercel
vercel login
```

### Set API Keys in Vercel
```bash
vercel env add PINECONE_API
# Paste: pcsk_your_pinecone_key_here

vercel env add OPENAI_API_KEY
# Paste: sk-your-openai-key-here

# Select: Production, Preview, Development (all)
```

### Deploy
```bash
vercel
```

That's it! You'll get a live URL like `https://bullbot.vercel.app`

---

## ğŸ“š Documentation

- **VERCEL_DEPLOYMENT.md** - Complete Vercel deployment guide
- **SETUP_COMPLETE.md** - Original full setup documentation

---

## ğŸ¯ Architecture Comparison

### Old (Complex):
```
Client â†’ Express â†’ Flask (3 servers, 3 platforms)
```

### New (Simple):
```
Client â†’ Flask API (1 platform: Vercel)
```

### Benefits:
- âœ… Free hosting
- âœ… One command deployment
- âœ… Auto-scaling
- âœ… HTTPS included
- âœ… No server management

---

## ğŸ’° Costs

- **Vercel:** Free
- **Pinecone:** Free tier (1 index)
- **OpenAI:** ~$0.002/request

**Total:** $0-5/month for MVP

---

## ğŸ†˜ Quick Troubleshooting

**"OpenAI quota exceeded"** â†’ Add credits or new key  
**"Pinecone index not found"** â†’ Create index first  
**"Port in use"** â†’ Kill process: `lsof -i :8000`  
**Cold start slow** â†’ Normal for first request (~10-30s)

---

## Ready to Deploy? 

1. âœ… Pinecone index created
2. âœ… OpenAI key working
3. âœ… Data uploaded to Pinecone
4. Run: `vercel`

ğŸ‰ **You'll have a live chatbot in 2 minutes!**
